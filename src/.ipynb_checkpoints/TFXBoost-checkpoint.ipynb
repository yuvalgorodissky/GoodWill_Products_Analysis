{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22d5e6ab-0b87-4463-9200-ba0726f0dcf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import xgboost as xgb\n",
    "from scipy.sparse import hstack\n",
    "from tqdm import tqdm\n",
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from preprocessing import load_and_combine_csv_files,clean_and_label_data\n",
    "import joblib\n",
    "import os\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "231494f5-0535-47cb-b78c-14b66b9e7838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process data with TF-IDF\n",
    "def process_data_with_tfidf(df, title_vectorizer=None, desc_vectorizer=None, is_training=False):\n",
    "    \"\"\"\n",
    "    Process data by applying TF-IDF vectorization.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input data frame.\n",
    "        title_vectorizer (TfidfVectorizer, optional): The vectorizer for the 'title' column.\n",
    "        desc_vectorizer (TfidfVectorizer, optional): The vectorizer for the 'description' column.\n",
    "        is_training (bool): Whether the function is being used in training mode (fitting vectorizers).\n",
    "\n",
    "    Returns:\n",
    "        tuple: Sparse matrices for title and description features, and fitted vectorizers (if training).\n",
    "    \"\"\"\n",
    "    if is_training:\n",
    "        if title_vectorizer is None:\n",
    "            title_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "        if desc_vectorizer is None:\n",
    "            desc_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "        # Fit and transform during training\n",
    "        title_tfidf = title_vectorizer.fit_transform(df['title'])\n",
    "        desc_tfidf = desc_vectorizer.fit_transform(df['description'])\n",
    "    else:\n",
    "        # Transform only during inference\n",
    "        title_tfidf = title_vectorizer.transform(df['title'])\n",
    "        desc_tfidf = desc_vectorizer.transform(df['description'])\n",
    "\n",
    "    return title_tfidf, desc_tfidf, title_vectorizer, desc_vectorizer\n",
    "\n",
    "# Function to split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14f2284e-d2eb-47f2-88f5-99763ac4ccea",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "nothing to repeat at position 73",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m combined_df \u001b[38;5;241m=\u001b[39m load_and_combine_csv_files(directory, base_filename, num_files)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Clean and label the data\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m cleaned_df, le_state, le_category \u001b[38;5;241m=\u001b[39m \u001b[43mclean_and_label_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Apply log transformation to the target variable\u001b[39;00m\n\u001b[1;32m     13\u001b[0m cleaned_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurrentPrice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog1p(cleaned_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurrentPrice\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/sise/eliorsu-group/yuvalgor/courses/Data-mining-in-Big-Data/src/preprocessing.py:78\u001b[0m, in \u001b[0;36mclean_and_label_data\u001b[0;34m(df, le_state, le_category)\u001b[0m\n\u001b[1;32m     69\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mstr\u001b[39m(x)\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mnotna(x) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# Filter out records\u001b[39;00m\n\u001b[1;32m     72\u001b[0m mask \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;66;03m# Basic validity checks\u001b[39;00m\n\u001b[1;32m     74\u001b[0m         (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurrentPrice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m&\u001b[39m\n\u001b[1;32m     75\u001b[0m         (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimageUrls\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnotna()) \u001b[38;5;241m&\u001b[39m\n\u001b[1;32m     76\u001b[0m         (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimageUrls\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m&\u001b[39m\n\u001b[1;32m     77\u001b[0m         \u001b[38;5;66;03m# Warning phrase check\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m         (\u001b[38;5;241m~\u001b[39m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtitle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontains\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m|\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwarning_phrases\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[1;32m     79\u001b[0m )\n\u001b[1;32m     81\u001b[0m df \u001b[38;5;241m=\u001b[39m df[mask]\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# Apply label encoding\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/goodwill_proj/lib/python3.9/site-packages/pandas/core/strings/accessor.py:137\u001b[0m, in \u001b[0;36mforbid_nonstring_types.<locals>._forbid_nonstring_types.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    133\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot use .str.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with values of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    134\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minferred dtype \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    135\u001b[0m     )\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/goodwill_proj/lib/python3.9/site-packages/pandas/core/strings/accessor.py:1327\u001b[0m, in \u001b[0;36mStringMethods.contains\u001b[0;34m(self, pat, case, flags, na, regex)\u001b[0m\n\u001b[1;32m   1200\u001b[0m \u001b[38;5;129m@forbid_nonstring_types\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbytes\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   1201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcontains\u001b[39m(\n\u001b[1;32m   1202\u001b[0m     \u001b[38;5;28mself\u001b[39m, pat, case: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, flags: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, na\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, regex: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1203\u001b[0m ):\n\u001b[1;32m   1204\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;124;03m    Test if pattern or regex is contained within a string of a Series or Index.\u001b[39;00m\n\u001b[1;32m   1206\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;124;03m    dtype: bool\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1327\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m regex \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpat\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgroups:\n\u001b[1;32m   1328\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1329\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis pattern is interpreted as a regular expression, and has \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1330\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatch groups. To actually get the groups, use str.extract.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1331\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m   1332\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m   1333\u001b[0m         )\n\u001b[1;32m   1335\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39marray\u001b[38;5;241m.\u001b[39m_str_contains(pat, case, flags, na, regex)\n",
      "File \u001b[0;32m~/.conda/envs/goodwill_proj/lib/python3.9/re.py:252\u001b[0m, in \u001b[0;36mcompile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompile\u001b[39m(pattern, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompile a regular expression pattern, returning a Pattern object.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/goodwill_proj/lib/python3.9/re.py:304\u001b[0m, in \u001b[0;36m_compile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sre_compile\u001b[38;5;241m.\u001b[39misstring(pattern):\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfirst argument must be string or compiled pattern\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 304\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[43msre_compile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (flags \u001b[38;5;241m&\u001b[39m DEBUG):\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(_cache) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m _MAXCACHE:\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;66;03m# Drop the oldest item\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/goodwill_proj/lib/python3.9/sre_compile.py:788\u001b[0m, in \u001b[0;36mcompile\u001b[0;34m(p, flags)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isstring(p):\n\u001b[1;32m    787\u001b[0m     pattern \u001b[38;5;241m=\u001b[39m p\n\u001b[0;32m--> 788\u001b[0m     p \u001b[38;5;241m=\u001b[39m \u001b[43msre_parse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    790\u001b[0m     pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/goodwill_proj/lib/python3.9/sre_parse.py:955\u001b[0m, in \u001b[0;36mparse\u001b[0;34m(str, flags, state)\u001b[0m\n\u001b[1;32m    952\u001b[0m state\u001b[38;5;241m.\u001b[39mstr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m\n\u001b[1;32m    954\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 955\u001b[0m     p \u001b[38;5;241m=\u001b[39m \u001b[43m_parse_sub\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mSRE_FLAG_VERBOSE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m Verbose:\n\u001b[1;32m    957\u001b[0m     \u001b[38;5;66;03m# the VERBOSE flag was switched on inside the pattern.  to be\u001b[39;00m\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;66;03m# on the safe side, we'll parse the whole thing again...\u001b[39;00m\n\u001b[1;32m    959\u001b[0m     state \u001b[38;5;241m=\u001b[39m State()\n",
      "File \u001b[0;32m~/.conda/envs/goodwill_proj/lib/python3.9/sre_parse.py:444\u001b[0m, in \u001b[0;36m_parse_sub\u001b[0;34m(source, state, verbose, nested)\u001b[0m\n\u001b[1;32m    442\u001b[0m start \u001b[38;5;241m=\u001b[39m source\u001b[38;5;241m.\u001b[39mtell()\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m     itemsappend(\u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnested\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m                       \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnested\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitems\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sourcematch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/goodwill_proj/lib/python3.9/sre_parse.py:669\u001b[0m, in \u001b[0;36m_parse\u001b[0;34m(source, state, verbose, nested, first)\u001b[0m\n\u001b[1;32m    667\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m item \u001b[38;5;129;01mor\u001b[39;00m item[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m AT:\n\u001b[0;32m--> 669\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m source\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnothing to repeat\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    670\u001b[0m                        source\u001b[38;5;241m.\u001b[39mtell() \u001b[38;5;241m-\u001b[39m here \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(this))\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m item[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m _REPEATCODES:\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m source\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiple repeat\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    673\u001b[0m                        source\u001b[38;5;241m.\u001b[39mtell() \u001b[38;5;241m-\u001b[39m here \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(this))\n",
      "\u001b[0;31merror\u001b[0m: nothing to repeat at position 73"
     ]
    }
   ],
   "source": [
    "# Parameters for loading data\n",
    "directory = \"/sise/eliorsu-group/yuvalgor/courses/Data-mining-in-Big-Data/datasets/\"\n",
    "base_filename = \"goodwill_items_job_\"\n",
    "num_files = 30\n",
    "\n",
    "# Load and combine the CSV files\n",
    "combined_df = load_and_combine_csv_files(directory, base_filename, num_files)\n",
    "\n",
    "# Clean and label the data\n",
    "cleaned_df, le_state, le_category = clean_and_label_data(combined_df)\n",
    "\n",
    "# Apply log transformation to the target variable\n",
    "cleaned_df['currentPrice'] = np.log1p(cleaned_df['currentPrice'])\n",
    "\n",
    "# Split the data into train, validation, and test sets\n",
    "train_df = cleaned_df.iloc[:100000]\n",
    "val_df = cleaned_df.iloc[100000:150000]\n",
    "test_df = cleaned_df.iloc[150000:]\n",
    "\n",
    "# Combine training and validation sets for initial processing\n",
    "train_val_df = pd.concat([train_df, val_df], axis=0)\n",
    "\n",
    "# Perform TF-IDF processing on the combined training and validation set\n",
    "title_train_val, desc_train_val, title_vectorizer, desc_vectorizer = process_data_with_tfidf(\n",
    "    train_val_df, is_training=True\n",
    ")\n",
    "\n",
    "# Perform TF-IDF processing on the test set using the fitted vectorizers\n",
    "title_test, desc_test, _, _ = process_data_with_tfidf(\n",
    "    test_df, title_vectorizer=title_vectorizer, desc_vectorizer=desc_vectorizer, is_training=False\n",
    ")\n",
    "\n",
    "# Separate training and validation features\n",
    "title_features_train = title_train_val[:len(train_df)]\n",
    "desc_features_train = desc_train_val[:len(train_df)]\n",
    "title_features_val = title_train_val[len(train_df):]\n",
    "desc_features_val = desc_train_val[len(train_df):]\n",
    "\n",
    "# Combine all features for training\n",
    "state_encoded_train = train_df['state_encoded'].to_numpy()\n",
    "category_encoded_train = train_df['category_encoded'].to_numpy()\n",
    "\n",
    "feature_matrix_train = hstack([\n",
    "    title_features_train,\n",
    "    desc_features_train,\n",
    "    state_encoded_train.reshape(-1, 1),\n",
    "    category_encoded_train.reshape(-1, 1)\n",
    "])\n",
    "\n",
    "# Combine all features for validation\n",
    "state_encoded_val = val_df['state_encoded'].to_numpy()\n",
    "category_encoded_val = val_df['category_encoded'].to_numpy()\n",
    "\n",
    "feature_matrix_val = hstack([\n",
    "    title_features_val,\n",
    "    desc_features_val,\n",
    "    state_encoded_val.reshape(-1, 1),\n",
    "    category_encoded_val.reshape(-1, 1)\n",
    "])\n",
    "\n",
    "# Combine all features for testing\n",
    "state_encoded_test = test_df['state_encoded'].to_numpy()\n",
    "category_encoded_test = test_df['category_encoded'].to_numpy()\n",
    "\n",
    "feature_matrix_test = hstack([\n",
    "    title_test,\n",
    "    desc_test,\n",
    "    state_encoded_test.reshape(-1, 1),\n",
    "    category_encoded_test.reshape(-1, 1)\n",
    "])\n",
    "\n",
    "print(\"\\nAfter cleaning, splitting, and TF-IDF processing:\")\n",
    "print(\"Feature matrix (training) shape:\", feature_matrix_train.shape)\n",
    "print(\"Feature matrix (validation) shape:\", feature_matrix_val.shape)\n",
    "print(\"Feature matrix (test) shape:\", feature_matrix_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7792c5c4-1cf8-4656-97a3-b0e8f9e6d4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "X_train = feature_matrix_train\n",
    "X_val = feature_matrix_val\n",
    "X_test = feature_matrix_test\n",
    "y_train = train_df['currentPrice'].to_numpy()\n",
    "y_val = val_df['currentPrice'].to_numpy()\n",
    "y_test = test_df['currentPrice'].to_numpy()\n",
    "\n",
    "# Convert sparse matrices to CSR format for efficient processing\n",
    "X_train = X_train.tocsr()\n",
    "X_val = X_val.tocsr()\n",
    "X_test = X_test.tocsr()\n",
    "\n",
    "# Log the shapes of the prepared features and targets\n",
    "print(\"\\nPrepared features and targets:\")\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_val shape:\", y_val.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effbed92-3193-40d7-a82d-f95674cb9eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Prepare CatBoost Pools for training and validation\n",
    "train_pool = Pool(data=X_train, label=y_train)\n",
    "val_pool = Pool(data=X_val, label=y_val)\n",
    "\n",
    "# Initialize the CatBoost Regressor\n",
    "model = CatBoostRegressor(\n",
    "    iterations=2000,\n",
    "    learning_rate=0.1,\n",
    "    depth=6,\n",
    "    loss_function='RMSE',\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "# Train the model with validation set\n",
    "model.fit(train_pool, eval_set=val_pool, use_best_model=True)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_log = model.predict(X_test)\n",
    "y_pred = np.expm1(y_pred_log)  # Convert predictions back from log scale if applicable\n",
    "y_test_actual = np.expm1(y_test)  # Convert actual test values back from log scale if applicable\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test_actual, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test_actual, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"\\nTest Set Metrics:\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"R2 Score: {r2:.4f}\")\n",
    "\n",
    "# Save the trained model\n",
    "save_dir = '/sise/eliorsu-group/yuvalgor/courses/Data-mining-in-Big-Data/models'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "model_name = 'CatBoostPricePrediction'\n",
    "model_path = os.path.join(save_dir, f'{model_name}.cbm')\n",
    "model.save_model(model_path)\n",
    "print(f'\\nModel saved at: {model_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d705b87-5566-476d-8881-03d1864a98d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred_log = model.predict(X_test)  # Predictions are in log scale if trained with log-transformed targets\n",
    "y_pred = np.expm1(y_pred_log)  # Convert predictions back to original scale if applicable\n",
    "y_test_actual = np.expm1(y_test)  # Convert actual test values back to original scale if applicable\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test_actual, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test_actual, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"\\nFinal Test Set Metrics:\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"R2 Score: {r2:.4f}\")\n",
    "\n",
    "# Save the trained model if not already saved\n",
    "save_dir = '/sise/eliorsu-group/yuvalgor/courses/Data-mining-in-Big-Data/models'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "model_name = 'CatBoostPricePrediction_TF_IDF'\n",
    "model_path = os.path.join(save_dir, f'{model_name}.cbm')\n",
    "model.save_model(model_path)\n",
    "print(f'\\nModel saved at: {model_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff731f37-26d4-4d98-9e9c-edb0cd7443fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "# Add predictions and calculate metrics\n",
    "test_df['predicted_price'] = y_pred\n",
    "test_df['actual_price'] = y_test_actual\n",
    "test_df['price_difference'] = test_df['predicted_price'] - test_df['actual_price']\n",
    "test_df['price_difference_pct'] = ((test_df['actual_price'] - test_df['predicted_price']) / test_df['predicted_price']) * -100\n",
    "\n",
    "# Create analysis dataframe with all relevant fields\n",
    "analysis_df = test_df[[\n",
    "   'title',\n",
    "   'actual_price',\n",
    "   'predicted_price', \n",
    "   'price_difference',\n",
    "   'price_difference_pct',\n",
    "   'mainCategory',\n",
    "   'description',\n",
    "   'pickupState',\n",
    "   'imageUrls',\n",
    "   'itemId'\n",
    "]].copy()\n",
    "\n",
    "# Round numeric columns\n",
    "numeric_cols = ['actual_price', 'predicted_price', 'price_difference', 'price_difference_pct']\n",
    "analysis_df[numeric_cols] = analysis_df[numeric_cols].round(2)\n",
    "\n",
    "# Sort by price difference percentage (descending order - largest gap first)\n",
    "analysis_df = analysis_df.sort_values('price_difference', ascending=False)\n",
    "\n",
    "# Save results with model name and timestamp\n",
    "model_name = \"CatBoostPricePrediction_TF_IDF\"\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M')\n",
    "filename = f\"{model_name}_undervalued_products_{timestamp}.csv\"\n",
    "save_path = f\"/sise/eliorsu-group/yuvalgor/courses/Data-mining-in-Big-Data/results/{filename}\"\n",
    "analysis_df.to_csv(save_path, index=False)\n",
    "print(f\"Analysis results saved at {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3df8ae-f9cf-4f30-a630-e569f9569780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b76567f-358a-48f3-846c-8fe8347d5910",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (goodwill_proj)",
   "language": "python",
   "name": "goodwill_proj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
