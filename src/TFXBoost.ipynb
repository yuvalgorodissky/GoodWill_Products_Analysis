{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22d5e6ab-0b87-4463-9200-ba0726f0dcf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import xgboost as xgb\n",
    "from scipy.sparse import hstack\n",
    "from tqdm import tqdm\n",
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from preprocessing import load_and_combine_csv_files,clean_and_label_data\n",
    "import joblib\n",
    "import os\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "231494f5-0535-47cb-b78c-14b66b9e7838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process data with TF-IDF\n",
    "def process_data_with_tfidf(df, title_vectorizer=None, desc_vectorizer=None, is_training=False):\n",
    "    \"\"\"\n",
    "    Process data by applying TF-IDF vectorization.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input data frame.\n",
    "        title_vectorizer (TfidfVectorizer, optional): The vectorizer for the 'title' column.\n",
    "        desc_vectorizer (TfidfVectorizer, optional): The vectorizer for the 'description' column.\n",
    "        is_training (bool): Whether the function is being used in training mode (fitting vectorizers).\n",
    "\n",
    "    Returns:\n",
    "        tuple: Sparse matrices for title and description features, and fitted vectorizers (if training).\n",
    "    \"\"\"\n",
    "    if is_training:\n",
    "        if title_vectorizer is None:\n",
    "            title_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "        if desc_vectorizer is None:\n",
    "            desc_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "        # Fit and transform during training\n",
    "        title_tfidf = title_vectorizer.fit_transform(df['title'])\n",
    "        desc_tfidf = desc_vectorizer.fit_transform(df['description'])\n",
    "    else:\n",
    "        # Transform only during inference\n",
    "        title_tfidf = title_vectorizer.transform(df['title'])\n",
    "        desc_tfidf = desc_vectorizer.transform(df['description'])\n",
    "\n",
    "    return title_tfidf, desc_tfidf, title_vectorizer, desc_vectorizer\n",
    "\n",
    "# Function to split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14f2284e-d2eb-47f2-88f5-99763ac4ccea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After cleaning, splitting, and TF-IDF processing:\n",
      "Feature matrix (training) shape: (100000, 10002)\n",
      "Feature matrix (validation) shape: (50000, 10002)\n",
      "Feature matrix (test) shape: (1087432, 10002)\n"
     ]
    }
   ],
   "source": [
    "# Parameters for loading data\n",
    "directory = \"/sise/eliorsu-group/yuvalgor/courses/Data-mining-in-Big-Data/datasets/\"\n",
    "base_filename = \"goodwill_items_job_\"\n",
    "num_files = 30\n",
    "\n",
    "# Load and combine the CSV files\n",
    "combined_df = load_and_combine_csv_files(directory, base_filename, num_files)\n",
    "\n",
    "# Clean and label the data\n",
    "cleaned_df, le_state, le_category = clean_and_label_data(combined_df)\n",
    "\n",
    "# Apply log transformation to the target variable\n",
    "cleaned_df['currentPrice'] = np.log1p(cleaned_df['currentPrice'])\n",
    "\n",
    "# Split the data into train, validation, and test sets\n",
    "train_df = cleaned_df.iloc[:100000]\n",
    "val_df = cleaned_df.iloc[100000:150000]\n",
    "test_df = cleaned_df.iloc[150000:]\n",
    "\n",
    "# Combine training and validation sets for initial processing\n",
    "train_val_df = pd.concat([train_df, val_df], axis=0)\n",
    "\n",
    "# Perform TF-IDF processing on the combined training and validation set\n",
    "title_train_val, desc_train_val, title_vectorizer, desc_vectorizer = process_data_with_tfidf(\n",
    "    train_val_df, is_training=True\n",
    ")\n",
    "\n",
    "# Perform TF-IDF processing on the test set using the fitted vectorizers\n",
    "title_test, desc_test, _, _ = process_data_with_tfidf(\n",
    "    test_df, title_vectorizer=title_vectorizer, desc_vectorizer=desc_vectorizer, is_training=False\n",
    ")\n",
    "\n",
    "# Separate training and validation features\n",
    "title_features_train = title_train_val[:len(train_df)]\n",
    "desc_features_train = desc_train_val[:len(train_df)]\n",
    "title_features_val = title_train_val[len(train_df):]\n",
    "desc_features_val = desc_train_val[len(train_df):]\n",
    "\n",
    "# Combine all features for training\n",
    "state_encoded_train = train_df['state_encoded'].to_numpy()\n",
    "category_encoded_train = train_df['category_encoded'].to_numpy()\n",
    "\n",
    "feature_matrix_train = hstack([\n",
    "    title_features_train,\n",
    "    desc_features_train,\n",
    "    state_encoded_train.reshape(-1, 1),\n",
    "    category_encoded_train.reshape(-1, 1)\n",
    "])\n",
    "\n",
    "# Combine all features for validation\n",
    "state_encoded_val = val_df['state_encoded'].to_numpy()\n",
    "category_encoded_val = val_df['category_encoded'].to_numpy()\n",
    "\n",
    "feature_matrix_val = hstack([\n",
    "    title_features_val,\n",
    "    desc_features_val,\n",
    "    state_encoded_val.reshape(-1, 1),\n",
    "    category_encoded_val.reshape(-1, 1)\n",
    "])\n",
    "\n",
    "# Combine all features for testing\n",
    "state_encoded_test = test_df['state_encoded'].to_numpy()\n",
    "category_encoded_test = test_df['category_encoded'].to_numpy()\n",
    "\n",
    "feature_matrix_test = hstack([\n",
    "    title_test,\n",
    "    desc_test,\n",
    "    state_encoded_test.reshape(-1, 1),\n",
    "    category_encoded_test.reshape(-1, 1)\n",
    "])\n",
    "\n",
    "print(\"\\nAfter cleaning, splitting, and TF-IDF processing:\")\n",
    "print(\"Feature matrix (training) shape:\", feature_matrix_train.shape)\n",
    "print(\"Feature matrix (validation) shape:\", feature_matrix_val.shape)\n",
    "print(\"Feature matrix (test) shape:\", feature_matrix_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7792c5c4-1cf8-4656-97a3-b0e8f9e6d4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prepared features and targets:\n",
      "X_train shape: (100000, 10002)\n",
      "X_val shape: (50000, 10002)\n",
      "X_test shape: (1087432, 10002)\n",
      "y_train shape: (100000,)\n",
      "y_val shape: (50000,)\n",
      "y_test shape: (1087432,)\n"
     ]
    }
   ],
   "source": [
    "# Prepare features and target\n",
    "X_train = feature_matrix_train\n",
    "X_val = feature_matrix_val\n",
    "X_test = feature_matrix_test\n",
    "y_train = train_df['currentPrice'].to_numpy()\n",
    "y_val = val_df['currentPrice'].to_numpy()\n",
    "y_test = test_df['currentPrice'].to_numpy()\n",
    "\n",
    "# Convert sparse matrices to CSR format for efficient processing\n",
    "X_train = X_train.tocsr()\n",
    "X_val = X_val.tocsr()\n",
    "X_test = X_test.tocsr()\n",
    "\n",
    "# Log the shapes of the prepared features and targets\n",
    "print(\"\\nPrepared features and targets:\")\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_val shape:\", y_val.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "effbed92-3193-40d7-a82d-f95674cb9eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TBB Warning: The number of workers is currently limited to 5. The request for 63 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.7066230\ttest: 0.7049941\tbest: 0.7049941 (0)\ttotal: 380ms\tremaining: 12m 39s\n",
      "100:\tlearn: 0.5637382\ttest: 0.5772003\tbest: 0.5772003 (100)\ttotal: 27.4s\tremaining: 8m 35s\n",
      "200:\tlearn: 0.5338516\ttest: 0.5579658\tbest: 0.5579489 (199)\ttotal: 53.8s\tremaining: 8m 1s\n",
      "300:\tlearn: 0.5150157\ttest: 0.5465982\tbest: 0.5465982 (300)\ttotal: 1m 20s\tremaining: 7m 34s\n",
      "400:\tlearn: 0.5023813\ttest: 0.5422077\tbest: 0.5422077 (400)\ttotal: 1m 46s\tremaining: 7m 5s\n",
      "500:\tlearn: 0.4920193\ttest: 0.5374857\tbest: 0.5374857 (500)\ttotal: 2m 13s\tremaining: 6m 38s\n",
      "600:\tlearn: 0.4833525\ttest: 0.5338233\tbest: 0.5338233 (600)\ttotal: 2m 39s\tremaining: 6m 11s\n",
      "700:\tlearn: 0.4756045\ttest: 0.5308781\tbest: 0.5308781 (700)\ttotal: 3m 5s\tremaining: 5m 44s\n",
      "800:\tlearn: 0.4686341\ttest: 0.5290007\tbest: 0.5290007 (800)\ttotal: 3m 32s\tremaining: 5m 17s\n",
      "900:\tlearn: 0.4623243\ttest: 0.5278323\tbest: 0.5278323 (900)\ttotal: 3m 58s\tremaining: 4m 51s\n",
      "1000:\tlearn: 0.4567859\ttest: 0.5269444\tbest: 0.5268991 (996)\ttotal: 4m 24s\tremaining: 4m 24s\n",
      "1100:\tlearn: 0.4510446\ttest: 0.5257482\tbest: 0.5257365 (1099)\ttotal: 4m 51s\tremaining: 3m 57s\n",
      "1200:\tlearn: 0.4459989\ttest: 0.5251481\tbest: 0.5251405 (1199)\ttotal: 5m 17s\tremaining: 3m 31s\n",
      "1300:\tlearn: 0.4412918\ttest: 0.5242353\tbest: 0.5242314 (1299)\ttotal: 5m 43s\tremaining: 3m 4s\n",
      "1400:\tlearn: 0.4366424\ttest: 0.5233525\tbest: 0.5233525 (1400)\ttotal: 6m 10s\tremaining: 2m 38s\n",
      "1500:\tlearn: 0.4323343\ttest: 0.5227435\tbest: 0.5226678 (1485)\ttotal: 6m 36s\tremaining: 2m 11s\n",
      "1600:\tlearn: 0.4280973\ttest: 0.5220914\tbest: 0.5220914 (1600)\ttotal: 7m 2s\tremaining: 1m 45s\n",
      "1700:\tlearn: 0.4237238\ttest: 0.5216365\tbest: 0.5216365 (1700)\ttotal: 7m 28s\tremaining: 1m 18s\n",
      "1800:\tlearn: 0.4199505\ttest: 0.5214236\tbest: 0.5214236 (1800)\ttotal: 7m 55s\tremaining: 52.5s\n",
      "1900:\tlearn: 0.4162481\ttest: 0.5209367\tbest: 0.5209217 (1899)\ttotal: 8m 21s\tremaining: 26.1s\n",
      "1999:\tlearn: 0.4127190\ttest: 0.5205865\tbest: 0.5205402 (1968)\ttotal: 8m 47s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.5205401688\n",
      "bestIteration = 1968\n",
      "\n",
      "Shrink model to first 1969 iterations.\n",
      "\n",
      "Test Set Metrics:\n",
      "RMSE: 205.7087\n",
      "R2 Score: 0.0471\n",
      "\n",
      "Model saved at: /sise/eliorsu-group/yuvalgor/courses/Data-mining-in-Big-Data/models/CatBoostPricePrediction.cbm\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Prepare CatBoost Pools for training and validation\n",
    "train_pool = Pool(data=X_train, label=y_train)\n",
    "val_pool = Pool(data=X_val, label=y_val)\n",
    "\n",
    "# Initialize the CatBoost Regressor\n",
    "model = CatBoostRegressor(\n",
    "    iterations=2000,\n",
    "    learning_rate=0.1,\n",
    "    depth=6,\n",
    "    loss_function='RMSE',\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "# Train the model with validation set\n",
    "model.fit(train_pool, eval_set=val_pool, use_best_model=True)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_log = model.predict(X_test)\n",
    "y_pred = np.expm1(y_pred_log)  # Convert predictions back from log scale if applicable\n",
    "y_test_actual = np.expm1(y_test)  # Convert actual test values back from log scale if applicable\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test_actual, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test_actual, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"\\nTest Set Metrics:\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"R2 Score: {r2:.4f}\")\n",
    "\n",
    "# Save the trained model\n",
    "save_dir = '/sise/eliorsu-group/yuvalgor/courses/Data-mining-in-Big-Data/models'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "model_name = 'CatBoostPricePrediction'\n",
    "model_path = os.path.join(save_dir, f'{model_name}.cbm')\n",
    "model.save_model(model_path)\n",
    "print(f'\\nModel saved at: {model_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d705b87-5566-476d-8881-03d1864a98d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Test Set Metrics:\n",
      "RMSE: 205.7087\n",
      "R2 Score: 0.0471\n",
      "\n",
      "Model saved at: /sise/eliorsu-group/yuvalgor/courses/Data-mining-in-Big-Data/models/CatBoostPricePrediction_TF_IDF.cbm\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred_log = model.predict(X_test)  # Predictions are in log scale if trained with log-transformed targets\n",
    "y_pred = np.expm1(y_pred_log)  # Convert predictions back to original scale if applicable\n",
    "y_test_actual = np.expm1(y_test)  # Convert actual test values back to original scale if applicable\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test_actual, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test_actual, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"\\nFinal Test Set Metrics:\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"R2 Score: {r2:.4f}\")\n",
    "\n",
    "# Save the trained model if not already saved\n",
    "save_dir = '/sise/eliorsu-group/yuvalgor/courses/Data-mining-in-Big-Data/models'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "model_name = 'CatBoostPricePrediction_TF_IDF'\n",
    "model_path = os.path.join(save_dir, f'{model_name}.cbm')\n",
    "model.save_model(model_path)\n",
    "print(f'\\nModel saved at: {model_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff731f37-26d4-4d98-9e9c-edb0cd7443fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2717639/1974998450.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['predicted_price'] = y_pred\n",
      "/tmp/ipykernel_2717639/1974998450.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['actual_price'] = y_test_actual\n",
      "/tmp/ipykernel_2717639/1974998450.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['price_difference'] = test_df['predicted_price'] - test_df['actual_price']\n",
      "/tmp/ipykernel_2717639/1974998450.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['price_difference_pct'] = ((test_df['actual_price'] - test_df['predicted_price']) / test_df['predicted_price']) * -100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis results saved at /sise/eliorsu-group/yuvalgor/courses/Data-mining-in-Big-Data/results/CatBoostPricePrediction_TF_IDF_undervalued_products_20250109_1333.csv\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "# Add predictions and calculate metrics\n",
    "test_df['predicted_price'] = y_pred\n",
    "test_df['actual_price'] = y_test_actual\n",
    "test_df['price_difference'] = test_df['predicted_price'] - test_df['actual_price']\n",
    "test_df['price_difference_pct'] = ((test_df['actual_price'] - test_df['predicted_price']) / test_df['predicted_price']) * -100\n",
    "\n",
    "# Create analysis dataframe with all relevant fields\n",
    "analysis_df = test_df[[\n",
    "   'title',\n",
    "   'actual_price',\n",
    "   'predicted_price', \n",
    "   'price_difference',\n",
    "   'price_difference_pct',\n",
    "   'mainCategory',\n",
    "   'description',\n",
    "   'pickupState',\n",
    "   'imageUrls',\n",
    "   'itemId'\n",
    "]].copy()\n",
    "\n",
    "# Round numeric columns\n",
    "numeric_cols = ['actual_price', 'predicted_price', 'price_difference', 'price_difference_pct']\n",
    "analysis_df[numeric_cols] = analysis_df[numeric_cols].round(2)\n",
    "\n",
    "# Sort by price difference percentage (descending order - largest gap first)\n",
    "analysis_df = analysis_df.sort_values('price_difference', ascending=False)\n",
    "\n",
    "# Save results with model name and timestamp\n",
    "model_name = \"CatBoostPricePrediction_TF_IDF\"\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M')\n",
    "filename = f\"{model_name}_undervalued_products_{timestamp}.csv\"\n",
    "save_path = f\"/sise/eliorsu-group/yuvalgor/courses/Data-mining-in-Big-Data/results/{filename}\"\n",
    "analysis_df.to_csv(save_path, index=False)\n",
    "print(f\"Analysis results saved at {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3df8ae-f9cf-4f30-a630-e569f9569780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b76567f-358a-48f3-846c-8fe8347d5910",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (goodwill_proj)",
   "language": "python",
   "name": "goodwill_proj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
